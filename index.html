<!DOCTYPE html>
<html>
<head>
  <title>Face Login</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2"></script>
  <style>
    body {
      font-family: sans-serif;
      background: #f0f0f0;
      text-align: center;
      padding: 10px;
    }
    video, canvas {
      width: 90%;
      max-width: 350px;
      border-radius: 10px;
      margin: 10px auto;
    }
    button {
      display: block;
      width: 90%;
      max-width: 300px;
      margin: 10px auto;
      padding: 12px;
      font-size: 16px;
      border: none;
      border-radius: 8px;
      background-color: #007bff;
      color: white;
    }
    button:hover {
      background-color: #0056b3;
    }
  </style>
</head>
<body>

  <h2>Face Login Demo</h2>

  <video id="video" autoplay muted playsinline></video>
  <canvas id="overlay" style="display:none;"></canvas>

  <button onclick="registerFace()">Register Face</button>
  <button onclick="loginFace()">Login with Face</button>

  <!-- Sounds -->
  <audio id="successSound" src="https://actions.google.com/sounds/v1/cartoon/clang_and_wobble.ogg"></audio>
  <audio id="failSound" src="https://actions.google.com/sounds/v1/cartoon/wood_plank_flicks.ogg"></audio>

  <script>
    const video = document.getElementById("video");
    const successSound = document.getElementById("successSound");
    const failSound = document.getElementById("failSound");

    let savedDescriptor = null;
    let modelsLoaded = false;

    Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri('./models'),
      faceapi.nets.faceLandmark68Net.loadFromUri('./models'),
      faceapi.nets.faceRecognitionNet.loadFromUri('./models')
    ]).then(() => {
      modelsLoaded = true;
      startVideo();
    });

    function startVideo() {
      navigator.mediaDevices.getUserMedia({ video: {} })
        .then(stream => video.srcObject = stream)
        .catch(err => alert("Camera error: " + err));
    }

    async function detectFace() {
      if (!modelsLoaded) {
        alert("Face models still loading...");
        return null;
      }

      const detection = await faceapi
        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();

      return detection;
    }

    async function registerFace() {
      const result = await detectFace();
      if (!result) {
        failSound.play();
        alert("Face not detected. Try again.");
        return;
      }

      savedDescriptor = result.descriptor;
      successSound.play();
      alert("Face registered successfully.");
    }

    async function loginFace() {
      const result = await detectFace();
      if (!result || !savedDescriptor) {
        failSound.play();
        alert("No face registered or detected.");
        return;
      }

      const distance = faceapi.euclideanDistance(savedDescriptor, result.descriptor);
      if (distance < 0.5) {
        successSound.play();
        alert("Access Granted!");
      } else {
        failSound.play();
        alert("Access Denied!");
      }
    }
  </script>

</body>
</html>
